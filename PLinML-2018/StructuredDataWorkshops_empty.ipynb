{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StructuredDataWorkshops_empty.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"text","id":"IgH2y7jrLnfy"},"cell_type":"markdown","source":["\n","![alt text](http://gmum.net/images/logo.jpg =300x150)\n","\n","# Workshop Overview:\n","\n","\n","\n","1.  Image classification with a CNN\n","2.   Multisize Image Classification with classical CNN\n","3.   Set Aggregation Network for Multisize Image classification\n","\n"]},{"metadata":{"colab_type":"code","id":"QsUtMDD4I_KI","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import itertools\n","import cv2\n","\n","from tensorflow.keras.datasets import cifar10\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"BYbZRUeEz5BG"},"cell_type":"markdown","source":["# 1. Image classification\n","\n","Heading towards a mulitsize image classfication, we will first create and train a network for classical Cifar-10 image classification. The cifar train dataset consist of 50000 RGB images of size 32x32.  The code written in this stage will be later used in next sections and is a preliminary before heading to the problem of multisize image classification\n","\n"]},{"metadata":{"colab_type":"text","id":"aWVgWvff-Iky"},"cell_type":"markdown","source":["** 1.1. Load the data **  \n","The following function loads the CIFAR-10 dataset (and downloads it, if you haven't made it yet) and transforms the labels to one-hot-encoddings."]},{"metadata":{"colab_type":"code","id":"QYjruDyp-HH7","colab":{}},"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","\n","n_classes = 10\n","\n","X_train = X_train / 255.\n","X_test = X_test / 255.\n","\n","valid_size = len(X_test)//2\n","X_valid = X_test[:valid_size]\n","y_valid = y_test[:valid_size]\n","X_test = X_test[valid_size:]\n","y_test = y_test[valid_size:]\n","\n","\n","with tf.Session() as sess:\n","    y_train = tf.one_hot(y_train, n_classes).eval()\n","    y_test = tf.one_hot(y_test, n_classes).eval()\n","    y_valid = tf.one_hot(y_valid, n_classes).eval()\n","    \n","y_train = y_train.reshape(-1, n_classes)\n","y_test = y_test.reshape(-1, n_classes)\n","y_valid = y_valid.reshape(-1, n_classes)\n","\n","print(X_train.shape, y_train.shape)\n","print(X_test.shape, y_test.shape)\n","print(X_valid.shape, y_valid.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"3NgCRUghuvjO"},"cell_type":"markdown","source":["** 1.2. Define auxillary functions**  \n","The function below calculates the accuracy  for a dataset, where:\n","\n","\n","*   `sess` - is the opened session with trained model\n","*   `dataset` is the dataset to evaluate on\n","*   `correct_sum` is the sum of all correct predictions\n","*   `x_placeholder` - is the placeholder for the inputs\n","*    `batch_size` - is the size of one batch, default to 500\n","\n","We will use this function later to evaluate our models.\n","\n"]},{"metadata":{"colab_type":"code","id":"RQSXFleE77mf","colab":{}},"cell_type":"code","source":["def calculate_accuracy_batch(sess, dataset, y_dataset, correct_sum, x_placeholder, batch_size=500):\n","    validation_accuracy = 0.\n","    for j in list(range(0, dataset.shape[0], batch_size)):\n","        good_pred = sess.run(correct_sum, feed_dict={x_placeholder: dataset[j:(j+batch_size)], y: y_dataset[j:(j+batch_size)]})\n","        validation_accuracy += good_pred\n","\n","    validation_accuracy /= dataset.shape[0]\n","    return validation_accuracy"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"4RvIx93M-xYH"},"cell_type":"markdown","source":["** 1.3. Classical Convolutional Neural Network as a baseline**  \n","\n","In the following task you have to write a small CNN and train it on the CIFAR-10 dataset.\n","As the workshop time is limited, you should use small architecture. We propose the following:\n","\n","1. Convolutional layers:\n","    *   Convolutional layer (32 filters, 3x3 kernel, stride=1)\n","    *   Max pooling (2x2)\n","    *   Convolutional layer (64 filters, 3x3 kernel, stride=1)\n","    *   Max pooling (2x2)\n","    *   Convolutional layer (64 filters, 3x3 kernel, stride=1)\n","    *   Max pooling (2x2)\n","    \n","2. Flatten layers:\n","    *  One classical flatten layer.\n","    \n","3. Dense layers:\n","    *  Dense layer (128 units, ReLU as activation function)\n","    *  Output dense layer (`n_class` units, no activation function -> instead of using softmax activation + cross entropy loss function, in order to achieve better numerical stability return the logits here, and next use the [`softmax_cross_entropy_with_logits_v2`](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2) cost function)\n","\n"]},{"metadata":{"colab_type":"code","id":"JkcliSyGpuxD","colab":{}},"cell_type":"code","source":["tf.reset_default_graph()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"hqrre2nv08m0"},"cell_type":"markdown","source":["** 1.4. Define the network architecture **\n","\n","Please complete the following functions, which define the network layers, as described above. We suggest using the [tf.layers](https://www.tensorflow.org/api_docs/python/tf/layers) module.\n","\n","You will probably need the following layers:\n","\n","*  [conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)\n","*  [max_pooling2d](https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling2d)\n","*  [flatten](https://www.tensorflow.org/api_docs/python/tf/layers/flatten)\n","*  [dense](https://www.tensorflow.org/api_docs/python/tf/layers/dense)\n","\n","Please write the code in variable scopes."]},{"metadata":{"colab_type":"code","id":"--SSIoC3wsvF","colab":{}},"cell_type":"code","source":["def conv_layers(x):\n","    \"\"\"\n","    Write the function which takes the RGB image as input and then passes it\n","    through convolutional and max_pooling layers, as described in section 2.3. \n","    \"\"\"\n","    with tf.variable_scope('baseline_net', reuse=tf.AUTO_REUSE):\n","        x_conv = ##\n","\n","    return x_conv\n","    \n","    \n","def flatten_layer(x):\n","    \"\"\"\n","    Write the function for flattening the feature maps obtained from the convolutional layers. \n","    \"\"\"\n","    x_flat = ##\n","    return x_flat\n","\n","  \n","def dense_layers(x):\n","    \"\"\"\n","    Write the function which takes the flattened ouput of convolutions and passes it \n","    through dense layers, as described in section 2.3.\n","    \"\"\"\n","    with tf.variable_scope('baseline_net', reuse=tf.AUTO_REUSE):\n","        logits = ##\n","    return logits\n","\n","\n","def create_network_1(x):\n","    \"\"\"\n","    This function is the pipeline for the image processing. The image is processed as follows:\n","    1. Apply the convolutional layers (function conv_layers).\n","    2. Flatten the image, before passing it to dense layers (function flatten_layer).\n","    3. Apply the dense layers to get the logits (function dense_layers).\n","    Return the logits. \n","    \"\"\"\n","    x_conv = conv_layers(x)\n","    x_flat = flatten_layer(x_conv)\n","    logits = dense_layers(x_flat)\n","    return logits"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"sbX3flOJ1afo"},"cell_type":"markdown","source":["** 1.5. Define the placeholders for training data**  \n","Remember about the propper shape for training images (in CIFAR-10 dataset every digit is a 32x32 RGB image). The labels are represented in one-hot-encoding. "]},{"metadata":{"colab_type":"code","id":"fBTsfA4_wsya","colab":{}},"cell_type":"code","source":["\"\"\" Define the input placeholder. \"\"\"\n","x = ##\n","\n","\"\"\" Define the true labels placeholder. \"\"\"\n","y = ##"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DHx9FxBNzZ64","colab_type":"text"},"cell_type":"markdown","source":["** 1.6. Create the logits**  "]},{"metadata":{"id":"RqVZObCtJCdO","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\" Create the logits. \"\"\"\n","logits = create_network_1(x)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"NtJrPEF34X9c"},"cell_type":"markdown","source":["** 1.7. Define the loss function and optimizer**  \n","\n","In this section you are asked to complete the loss function and optimization operation.  \n","*   As mentioned above, we will use the cross entropy loss. The loss is implemented in [`tf.nn.softmax_cross_entropy_with_logits_v2`](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2)\n","*   As the optimizer please use the [`Adam optimizer`](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer) with learning rate `1e-3` and other parameters set to their default values.\n","\n"]},{"metadata":{"colab_type":"code","id":"5ErwSzCFwxJS","colab":{}},"cell_type":"code","source":["\"\"\" Define the cross entropy loss function. Remember that for numerical\n","stability reasons we use the tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits) function. \n","You should not apply the softmax function on logits yourself. \"\"\"\n","\n","cross_entropy = ##\n","cross_entropy = ##\n","\n","learning_rate = 1e-3\n","\"\"\" Define the Adam optimizer with default parameters, that will minimize our cross_entropy loss function. \"\"\"\n","train_step = ##"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"TX8FDCe86CKQ"},"cell_type":"markdown","source":["** 1.8. Define the accurracy calculator**  \n","\n","The functions below define the accuracy and correct sum (unormalized accuracy, which will be later passed to an evaluation function on test dataset)."]},{"metadata":{"colab_type":"code","id":"ah8rudsN5uuO","colab":{}},"cell_type":"code","source":["correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n","correct_prediction = tf.cast(correct_prediction, tf.float32)\n","\n","accuracy = tf.reduce_mean(correct_prediction)\n","correct_sum = tf.reduce_sum(correct_prediction)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"Xkagavmh7ckc"},"cell_type":"markdown","source":["** 1.9. Train the Neural Network** \n","\n","In this exercise you are asked to train and evaluate the CNN network. Please complete the code for the train function, where:\n","\n","\n","*   `sess` - is the opened tf.Session, you may assume that the global variables have already been initialized. \n","*   `x_train` - is the train dataset.\n","*   `x_valid` - is the validation dataset. This is not obligatory, but you may use the validation dataset and  \n","the `calculate_accuracy_batch(x_valid, correct_sum, x)` function defined previously to monitor the network's score on out-of-train data.\n","*   `epoch_num` - the number of epochs. \n","*   `batch_size` - the size of one batch.\n"]},{"metadata":{"colab_type":"code","id":"kN84qIO-wxPp","colab":{}},"cell_type":"code","source":["print_every = 1\n","def train(sess, X_train, X_valid, y_train, y_valid, epoch_num, batch_size):\n","    val_accs_baseline = []\n","    set_size = X_train.shape[0]\n","    for epoch in range(epoch_num):\n","        for i in range(0, set_size, batch_size):\n","            \"\"\"\n","            Complete the training loop.\n","            \"\"\"\n","            ##\n","        \n","        if epoch % print_every == 0:\n","            val_acc = calculate_accuracy_batch(sess, X_valid, y_valid, correct_sum, x)\n","            val_accs_baseline.append(val_acc)\n","            print('Epoch: {0:d}, validation accuracy: {1:.3f}'.format(epoch, val_acc))\n","        \n","        # shuffle the dataset\n","        perm = np.random.permutation(set_size)\n","        X_train = X_train[perm, :]\n","        y_train = y_train[perm, :]\n","        \n","    return val_accs_baseline"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"YPyo-JWk0sep"},"cell_type":"markdown","source":["** 1.10. Run the code **  \n","The cell below runs the train function and outputs the classification accuracy on the test set."]},{"metadata":{"colab_type":"code","id":"TY8EyIL3xgJK","colab":{}},"cell_type":"code","source":["# some hyperparameters \n","epoch_num = 10\n","batch_size = 64\n","\n","with tf.Session() as sess:\n","    #initialize the session\n","    sess.run(tf.global_variables_initializer())\n","    baseline_accuracy = train(sess, X_train, X_valid, y_train, y_valid, epoch_num, batch_size)\n","    test_acc = calculate_accuracy_batch(sess, X_test, y_test, correct_sum, x)\n","    print('Final test accuracy: {0:.3f}'.format(test_acc))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aGiaHlymR6Cb","colab_type":"text"},"cell_type":"markdown","source":["**1.11. Plot the accuracy**"]},{"metadata":{"id":"bda_GthZRH-y","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.figure(figsize=(9,7))\n","\n","plt.plot(baseline_accuracy, label='Accuracy')\n","plt.ylim(0.2, 0.8)\n","\n","plt.ylabel(\"Accuracy\")\n","plt.xlabel(\"Epoch\")\n","\n","plt.legend(prop={'size': 15})\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v0L3O3uE13Gm","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"ZfT5JocjAQhO"},"cell_type":"markdown","source":["## 2. Multisize Image Classification : Training and testing with multisized images -- ConvNet with global max pooling.\n","\n","Now we will move to the task of multisize image classfication, where the input images may have different shapes. \n","A common approach to this problem is to resize all the images into the same shape and process them all together. Another solution is to write a separate network for each of the shapes. An altenrative method could incorporate the use of convolutional layers. However, as the convolution architecture is in fact shape-invaraint, the following head architecture (for exaple the layer right before the classifier) is not. A possible solution to this problem is to use global average on global max pooling layers. In this section we will use the later: i.e. the global max pooling. \n","\n","In the following task you have to write a CNN that can handle multisize images. Then train it on the CIFAR-10 dataset. For the purpose of this workshop we will create an artificial multisize image dataset by resizing the CIFAR-10 dataset to 56x56 and 20x20.\n","\n","The CNN architecture will be very similar to the one in section 2, so you may reuse your code. We propose the following archietcture:\n","\n","1. Convolutional layers:\n","    *   Convolutional layer (32 filters, 3x3 kernel, stride=1)\n","    *   Max pooling (2x2)\n","    *   Convolutional layer (64 filters, 3x3 kernel, stride=1)\n","    *   Max pooling (2x2)\n","    *   Convolutional layer (64 filters, 3x3 kernel, stride=1)\n","    *   Max pooling (2x2)\n","    \n","2. Flatten layers:\n","    * Global max pooling layer\n","    \n","3. Dense layers:\n","    * Dense layer (128 units, ReLU as activation function)\n","    * Dense layer (128 units, ReLU as activation function)\n","    * Output dense layer (`n_class` units, no activation function -> instead of using softmax activation + cross entropy loss function, in order to achieve better numerical stability return the logits here and next use the `softmax_cross_entropy_with_logits_v2` cost function)\n","\n","This task is a little bit harder, as now we have to classify images that are not in a single shape. This is crumbersome because, as you have seen earlier, placeholders need a predefined image shape. We can solve this problem in two different ways:\n","\n","1. Dynamic shaped placeholders -> this is the harder method, we won't use it here. However if you have enough time, you can try to implement it on your own.\n","2. Using more placeholders for the input data. Assuming we known the shapes beforehand (as in this situation), we can specify a separate placeholder for each of the shapes. \n","\n","\n","---\n","\n"]},{"metadata":{"id":"U8ve8dRXJCd5","colab_type":"text"},"cell_type":"markdown","source":["Comment:\n","We use an artificially resized cifar-10, as orginal multisized datasets are way to big for the purpose of this workshop. Moreover implementing the upcoming models to use those datasets efficiently in tensorflow is much more difficult.  "]},{"metadata":{"colab_type":"code","id":"TbaL3gyh766k","colab":{}},"cell_type":"code","source":["tf.reset_default_graph()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"Yn9ch9Am_Mdr"},"cell_type":"markdown","source":["** 2.1. Create the dataset **  \n","The function below augments the CIFAR-10 with resized images of 56x56 and 20x20 pixels. \n"]},{"metadata":{"colab_type":"code","id":"DVyB9aGB_KEP","colab":{}},"cell_type":"code","source":["train_chunk_size = len(X_train)//3\n","\n","X_train_res_56 = np.array(list(map(lambda x: cv2.resize(x, dsize=(56, 56), interpolation=cv2.INTER_CUBIC), X_train[:train_chunk_size])))\n","X_train_res_20 = np.array(list(map(lambda x: cv2.resize(x, dsize=(20, 20), interpolation=cv2.INTER_CUBIC), X_train[train_chunk_size:2*train_chunk_size])))\n","\n","X_test_res_56 = np.array(list(map(lambda x: cv2.resize(x, dsize=(56, 56), interpolation=cv2.INTER_CUBIC), X_test)))\n","X_test_res_20 = np.array(list(map(lambda x: cv2.resize(x, dsize=(20, 20), interpolation=cv2.INTER_CUBIC), X_test)))\n","\n","X_valid_res_56 = np.array(list(map(lambda x: cv2.resize(x, dsize=(56, 56), interpolation=cv2.INTER_CUBIC), X_valid)))\n","X_valid_res_20 = np.array(list(map(lambda x: cv2.resize(x, dsize=(20, 20), interpolation=cv2.INTER_CUBIC), X_valid)))\n","\n","X_train_res_32 = X_train[2*train_chunk_size:]\n","X_test_res_32 = X_test\n","X_valid_res_32 = X_valid\n","\n","y_train_56 = y_train[:train_chunk_size]\n","y_train_20 = y_train[train_chunk_size:2*train_chunk_size]\n","y_train_32 = y_train[2*train_chunk_size:]"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"2x4hrcd88mfp"},"cell_type":"markdown","source":["** 2.2 Define the network architecture **\n","\n","Please complete the following functions. \n","You will probably need the following layers:\n","\n","*  [conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)\n","*  [max_pooling2d](https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling2d)\n","*  [flatten](https://www.tensorflow.org/api_docs/python/tf/layers/flatten)\n","*  [dense](https://www.tensorflow.org/api_docs/python/tf/layers/dense)\n","\n","Remember to write the code using variable scopes, as we want to share the weights across layers for different input shapes. "]},{"metadata":{"colab_type":"code","id":"iDoJhU9u761w","colab":{}},"cell_type":"code","source":["def conv_layers(x):\n","    \"\"\"\n","    Write the function which takes the RGB image as input and then passes it\n","    through convolutional and max_pooling layers. \n","    \"\"\"\n","    with tf.variable_scope('max_pool_net', reuse=tf.AUTO_REUSE):\n","        x_conv = ##\n","        \n","    return x_conv\n","    \n","    \n","def dense_layers(x):\n","    \"\"\"\n","    Write the function which takes the output of global max pooling\n","    and then passes it through dense layers.\n","    \"\"\"\n","    with tf.variable_scope('max_pool_net', reuse=tf.AUTO_REUSE):\n","        logits = tf.layers.dense(inputs=x_flat, units=n_classes, name='FC_3') ##\n","        \n","    return logits\n","\n","    \n","def image_max_pooling(x):\n","    \"\"\"\n","    Write the function for global max_pooling over the filters.\n","    \"\"\"\n","    x_flat = ##\n","    return x_flat\n","\n","\n","def create_network_2(x):\n","    \"\"\"\n","    This function is the pipeline for the image processing. The image is processed as follows:\n","    1. Apply the convolutional layers.\n","    2. Use global max pooling on each filter of the returned image and then flatten it, before passing it to dense layers.\n","    3. Apply dense layers to get the logits.\n","    Return the logits.\n","    \"\"\"\n","    x_conv = conv_layers(x)\n","    x_flat = image_max_pooling(x_conv)\n","    logits = dense_layers(x_flat)\n","    return logits"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"5iacUx4K9-Bq"},"cell_type":"markdown","source":["**2.3 Define the placeholders for the training data and the logits **  \n","Remember about the propper shape for training images (in CIFAR-10 dataset every digit is a 32x32 RGB image). The labels are represented using one-hot-encoding. We also have to handle images with shapes 20x20 and 56x56. "]},{"metadata":{"colab_type":"code","id":"Zft0rYj976wC","colab":{}},"cell_type":"code","source":["\"\"\" Define the input placeholder. \"\"\"\n","x = ##\n","\n","\"\"\" Define the true labels placeholder. \"\"\"\n","y = ##\n","\n","\"\"\" You can consider using more placeholders \"\"\""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"MrJffvedAYSb"},"cell_type":"markdown","source":["** 2.4 Define the logits as the output from our CNN **\n","\n","Create the logits using the function from section 3.2."]},{"metadata":{"colab_type":"code","id":"zi98p9Ylvb2U","colab":{}},"cell_type":"code","source":["logits = create_network_2(x)\n","\n","\"\"\" If You created more placeholders, You have to handle them somehow.\n","    Maybe this is the time and place. \"\"\"\n","logits_20 = ##\n","logits_56 = ##"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"bcGG9q5-BLUJ"},"cell_type":"markdown","source":["** 2.5 Define the loss function and optimizer **\n","\n","In this section you are asked to complete the loss function and optimization operation.  \n","*   As mentioned above, we will use the cross entropy loss. The loss is implemented in [`tf.nn.softmax_cross_entropy_with_logits_v2`](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2)\n","*   As the optimizer please use the [`Adam optimizer`](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer) with learning rate `1e-3` and other parameters set to their default values."]},{"metadata":{"colab_type":"code","id":"Lxyjq_sDCAch","colab":{}},"cell_type":"code","source":["\"\"\" Define the cross entropy loss function \"\"\"\n","cross_entropy = ##\n","\n","\n","\"\"\" Define the Adam optimizer with default parameters, that will minimize our cross_entropy loss function. \"\"\"\n","train_step = ##"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"SZ9eHW2ECbXQ"},"cell_type":"markdown","source":["** 2.6. Define the accurracy calculator **\n","\n","The functions below define the accuracy and correct_sum operations for evaluating our model. "]},{"metadata":{"colab_type":"code","id":"e1jWVtAIBO9h","colab":{}},"cell_type":"code","source":["\"\"\" Create a vector that tells us, whether the predictions from our net (logits)\n","    are equal to the correct digit labels (y). \"\"\"\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n","correct_prediction = tf.cast(correct_prediction, tf.float32)\n","\n","\"\"\" Calculate the accurracy of correct predictions.\n","    You should also calculate the number of correct predictions as this is required by calculate_accuracy_batch function.\"\"\"\n","accuracy = tf.reduce_mean(correct_prediction)\n","correct_sum = tf.reduce_sum(correct_prediction)\n","\n","\n","\"\"\" It is also usefull to calculate the number and accurracy of correct predictions\n","    separately for images of different sizes. \"\"\"\n","# Correct predictions\n","correct_prediction_56 = tf.equal(tf.argmax(logits_56, 1), tf.argmax(y, 1))\n","correct_prediction_56 = tf.cast(correct_prediction_56, tf.float32)\n","\n","correct_prediction_20 = tf.equal(tf.argmax(logits_20, 1), tf.argmax(y, 1))\n","correct_prediction_20 = tf.cast(correct_prediction_20, tf.float32)\n","\n","# Accurracies\n","accuracy_56 = tf.reduce_mean(correct_prediction_56)\n","accuracy_20 = tf.reduce_mean(correct_prediction_20)\n","\n","correct_sum_56 = tf.reduce_sum(correct_prediction_56)\n","correct_sum_20 = tf.reduce_sum(correct_prediction_20)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"YXU55PlCMlZl"},"cell_type":"markdown","source":["**2.7. Train our Neural Network**  \n","\n","In this exercise you are asked to train and evaluate the CNN network. Please complete the code for the train function, where:\n","\n","*   `sess` - is the opened tf.Session, you may assume that the global variables have already been initialized.\n","*   `x_train` - is the train dataset.\n","*   `x_valid` - is the validation dataset. This is not obligatory, but you may use the validation dataset and  \n","the `calculate_accuracy_batch(x_valid, correct_sum, x)` function defined previously, to monitor the network score on out-of-train data.\n","*   `epoch_num` - number of epochs \n","*   `batch_size` - the size of one batch.\n","\n","This function trains and is evaluated on data of size 32x32, 56x56 and 20x20. "]},{"metadata":{"colab_type":"code","id":"qpnhWe_EMhZN","colab":{}},"cell_type":"code","source":["def train(sess, X_train, X_valid, y_train, y_valid, epoch_num, batch_size, print_every=1):\n","    val_accs_pooling = []\n","    val_accs_56 = []\n","    val_accs_20 = []\n","    set_size = X_train.shape[0]\n","    global X_train_res_56, y_train_56\n","    global X_train_res_20, y_train_20\n","    for epoch in range(epoch_num):\n","        for i in range(0, set_size, batch_size):\n","            \"\"\"\n","            Complete the training loop.\n","            \"\"\"\n","            ##\n","        \n","        if epoch % print_every == 0:\n","            val_acc = calculate_accuracy_batch(sess, X_valid, y_valid, correct_sum, x)\n","            acc_56 = calculate_accuracy_batch(sess, X_valid_res_56, y_valid, correct_sum_56, x_56)\n","            acc_20 = calculate_accuracy_batch(sess, X_valid_res_20, y_valid, correct_sum_20, x_20)\n","            \n","            val_accs_pooling.append(val_acc)\n","            val_accs_56.append(acc_56)\n","            val_accs_20.append(acc_20)           \n","\n","            print('Epoch: {0:d}, ACC: {1:.3f}, ACC (56): {2:.3f}, ACC (20): {3:.3f}'.format(epoch, val_acc, acc_56, acc_20))\n","        \n","        # shuffle the dataset\n","        perm = np.random.permutation(set_size)\n","        X_train = X_train[perm, :]\n","        y_train = y_train[perm, :]\n","        perm = np.random.permutation(len(X_train_res_56))\n","        X_train_res_56 = X_train_res_56[perm, :]\n","        y_train_56 = y_train_56[perm, :]\n","        perm = np.random.permutation(len(X_train_res_20))\n","        X_train_res_20 = X_train_res_20[perm, :]\n","        y_train_20 = y_train_20[perm, :]\n","\n","        \n","    max_pool_accuracy = {}\n","    max_pool_accuracy['Acc'] = val_accs_pooling\n","    max_pool_accuracy['Acc_20'] = val_accs_20\n","    max_pool_accuracy['Acc_56'] = val_accs_56\n","    \n","    return max_pool_accuracy"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"I-SXvGQeNYT-"},"cell_type":"markdown","source":["** 2.8. Run the code **  \n","Run the functions above, either by using the train function from section 3.7. "]},{"metadata":{"colab_type":"code","id":"VmYT9liBCSrb","colab":{}},"cell_type":"code","source":["epoch_num = 15\n","batch_size = 64\n","\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    max_pool_accuracy = train(sess, X_train_res_32, X_valid_res_32, y_train_32, y_valid, epoch_num, batch_size) \n","    test_acc = calculate_accuracy_batch(sess, X_test_res_32, y_test, correct_sum, x)\n","    test_acc_56 = calculate_accuracy_batch(sess, X_test_res_56, y_test, correct_sum_56, x_56)\n","    test_acc_20 = calculate_accuracy_batch(sess, X_test_res_20, y_test, correct_sum_20, x_20)\n","    print(\"Final test accuracy: Original: {0:.3f}, 56x56: {1:.3f}, 20x20: {2:.3f}\".format(test_acc, test_acc_56, test_acc_20))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YjTttQFOSAyF","colab_type":"text"},"cell_type":"markdown","source":["**2.9. Plot the accuracy**"]},{"metadata":{"id":"YsrAgBKQRbRi","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.figure(figsize=(9,7))\n","\n","plt.plot(max_pool_accuracy['Acc'], label='Accuracy (original)')\n","plt.plot(max_pool_accuracy['Acc_20'], label='Accuracy (20x20)')\n","plt.plot(max_pool_accuracy['Acc_56'], label='Accuracy (56x56)')\n","plt.ylim(0.2, 0.8)\n","\n","plt.ylabel(\"Accuracy\")\n","plt.xlabel(\"Epoch\")\n","\n","\n","plt.legend(prop={'size': 15})\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oTGAIFEMRbe5","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"vB8jnhmdCL8A"},"cell_type":"markdown","source":["## 3. Set Aggregate Network for multisize image classification\n","\n","In this section we will use the Set Aggregate Network instead of the Global Max Pooling. The architecture of the model will look like this:\n","\n","1. Convolutional layers (unchanged):\n","    *   Convolutional layer (32 filters, 5x5 kernel, strides=1)\n","    *   Max pooling (2x2)\n","    *   Convolutional layer (32 filters, 5x5 kernel, strides=1)\n","    *   Max pooling (2x2)\n","    \n","2. Flatten layers:\n","    * SAN layer (projection dim=128)\n","    \n","3. Dense layers:\n","    * Dense layer (128 units, ReLU as activation function)\n","    * Output dense layer (n_class units, no activation function -> instead of using softmax activation + cross entropy loss function, in order to have better numerical stability, we will return the logits here, and next we will use the softmax_cross_entropy_with_logits_v2 cost function)\n","    \n","The SAN layer takes a batch of sets as input and outputs a batch of representations of that input.  You will have to preprocess the output from the convolutional layers, before feeding them to SAN. Every image (3 dimensional feature map) has to be represented as a set of vectors of pixels accross the feature map channels:\n","\n","$$X_{feature\\ map} = \\{ v_{(1,1)}, ..., v_{(m,n)} \\}$$\n","where $v_{(i,j)}$ is the vector representation of the pixel along all channels at position (i,j), composed of:\n","\n","$$ ùë£(ùëñ,ùëó)=(normalized(ùëñ),normalized(ùëó),ùëùùëñùë•ùëíùëô^{(ùëñ,ùëó)}_1,...,ùëùùëñùë•ùëíùëô^{(ùëñ,ùëó)}_k), $$\n","\n","where $ùëùùëñùë•ùëíùëô^{(ùëñ,ùëó)}_l$ is the pixel at position $(i,j)$ in channel $l$.  \n","\n","The position of the pixel in feature map is normalized to fall in $(-1,1)$:\n","\n","$$normalized(i) = \\frac{2i}{m}-1$$  \n","$$normalized(j) = \\frac{2j}{n}-1$$\n","<br>\n","<br>\n","![](https://ww2.ii.uj.edu.pl/~z1101353/Feature_Map.png)\n","<br>\n","<br>\n","\n","Then the normalized image is processed by the SAN layer, which is given by:\n","\n","$$SAN(X_{feature\\ map}) = \\sum_{v \\in X_{feature\\ map}} ReLU(w^{T}v + b)$$ \n","\n","In the equation above you may use the mean instead of sum. \n","\n"]},{"metadata":{"colab_type":"code","id":"5atmhJtiCAMn","colab":{}},"cell_type":"code","source":["tf.reset_default_graph()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"WluKSt_MEXH9"},"cell_type":"markdown","source":["** 3.1. Define the network architecture **\n"]},{"metadata":{"colab_type":"text","id":"idbhKMftEhv9"},"cell_type":"markdown","source":["Please complete the following functions. \n","You will probably need the following layers and functions:\n","\n","*  [conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)\n","*  [conv1d](https://www.tensorflow.org/api_docs/python/tf/layers/conv1d) or  [tensordot](https://www.tensorflow.org/api_docs/python/tf/tensordot) for implementing the SAN layer. \n","*  [max_pooling2d](https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling2d)\n","*  [flatten](https://www.tensorflow.org/api_docs/python/tf/layers/flatten)\n","*  [dense](https://www.tensorflow.org/api_docs/python/tf/layers/dense)\n","*  [tf.map_fn](https://www.tensorflow.org/api_docs/python/tf/map_fn)\n","\n","Please write the code using variable scopes. "]},{"metadata":{"colab_type":"code","id":"MbmfNwvdCAAy","colab":{}},"cell_type":"code","source":["def conv_layers(x):\n","    \"\"\"\n","    Write the function which takes the RGB image as input and then passes it\n","    through convolutional and max_pooling layers. \n","    \"\"\"\n","    with tf.variable_scope('san_net', reuse=tf.AUTO_REUSE):\n","        x_conv = ##\n","    return x_conv\n","    \n","    \n","def dense_layers(x):\n","    \"\"\"\n","    Write the function which takes the output from SAN layer and processes it through dense layers.\n","    \"\"\"\n","    with tf.variable_scope('san_net', reuse=tf.AUTO_REUSE):\n","        logits = ##\n","        \n","    return logits\n","    \n","    \n","def san_layer(x, proj_dim):\n","    \"\"\"\n","    Write the function which takes the preprocessed, normalized feature maps returned from convolutional layers\n","    and passes it through the SAN layer.\n","    \"\"\"\n","    with tf.variable_scope('san_net', reuse=tf.AUTO_REUSE):\n","        x_reduced = ##\n","    return x_reduced\n","\n","\n","def iter_function(img): \n","    x_shape = img.shape[0].value \n","    y_shape = img.shape[1].value \n","    \n","    x_lim = np.arange(x_shape, dtype=np.int32) \n","    y_lim = np.arange(y_shape, dtype=np.int32) \n","    \n","    prod_ = list(itertools.product(x_lim, y_lim)) \n","    img_values = tf.gather_nd(img, prod_) \n","    \n","    x_lim_norm = np.linspace(start=-1., stop=1., num=x_shape) \n","    y_lim_norm = np.linspace(start=-1., stop=1., num=y_shape) \n","    \n","    prod_normalized = np.array(list(itertools.product(x_lim_norm, y_lim_norm))) \n","    \n","    return tf.concat([prod_normalized, img_values], axis=1) \n","    \n","    \n","def prepare_batch(batch_x):\n","    \"\"\"\n","    Write the function which takes the feature maps returned from convolutional layers and \n","    makes the SAN preprocessing.\n","    You can preprocess every single feature map separately, which is done by the `iter_function`\n","    above. To do so, apply the tf.map_fn along the samples from batch_x. \n","    \"\"\"\n","    x_prepared = ##\n","    return x_prepared\n","    \n","\n","def create_network_3(x, proj_dim=128):\n","    \"\"\"\n","    This function is the pipeline for the image processing. The image is processed as follows:\n","    1. Apply the convolutional layers.\n","    2. Prepare the conv nets output to be able to pass it through the SAN layer.\n","    3. Use the SAN layer, before passing the image to dense layers.\n","    3. Apply dense layers to get the logits.\n","    \"\"\"\n","    x_conv = conv_layers(x)\n","    x_prepared = prepare_batch(x_conv)\n","    x_flat = san_layer(x_prepared, proj_dim)\n","    logits = dense_layers(x_flat)\n","    return logits"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"VRBdabnuC3Iv"},"cell_type":"markdown","source":["** 3.2  Define the placeholders for training data. **\n","\n","This code is the same as in section 3.3, so you may just copy it."]},{"metadata":{"colab_type":"code","id":"3gMUgWlRCihl","colab":{}},"cell_type":"code","source":["\"\"\" Define the input placeholder. \"\"\"\n","x = ##\n","\n","\"\"\" Define the true labels placeholder. \"\"\"\n","y = ##\n","\n","\"\"\" You can consider using more placeholders \"\"\""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"o3XoZ8tVC7Kj"},"cell_type":"markdown","source":["** 3.3 Define the logits as the output from our CNN **\n","\n","Create the logits using the function from section 4.1"]},{"metadata":{"colab_type":"code","id":"ubRCpMr7vmfc","colab":{}},"cell_type":"code","source":["logits = create_network_3(x)\n","\n","\"\"\" If You created more placeholders, You have to handle them somehow.\n","    Maybe this is the time and this is the place. \"\"\""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"VdaLZoy9C-xp"},"cell_type":"markdown","source":["** 3.4 Define the loss and optimizer **\n","\n","In this section you are asked to complete the loss function and optimization operation.  \n","*   As mentioned above, we will use the cross entropy loss. The loss is implemented in [`tf.nn.softmax_cross_entropy_with_logits_v2`](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2)\n","*   As the optimizer please use the [`Adam optimizer`](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer) with learning rate `1e-3` and other parameters set to their default values."]},{"metadata":{"colab_type":"code","id":"OxkAaUWzCYml","colab":{}},"cell_type":"code","source":["\"\"\" Define the cross entropy loss function \"\"\"\n","cross_entropy = ##\n","\n","\n","\"\"\" Define the Adam optimizer with default parameters, that will minimize our cross_entropy loss function. \"\"\"\n","train_step = ##"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"UUOgbmUqDD0U"},"cell_type":"markdown","source":["** 3.5 Define the accurracy calculator **  \n","\n","The functions below define the accuracy and correct_sum operations for evaluating our model. \n"]},{"metadata":{"colab_type":"code","id":"j-sdVH8rB5RE","colab":{}},"cell_type":"code","source":["\"\"\" Create a vector that tells us, whether the predictions from our net (logits)\n","    are equal to the correct digit labels (y). \"\"\"\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1)) \n","correct_prediction = tf.cast(correct_prediction, tf.float32) \n","\n","\"\"\" Calculate the accurracy of correct predictions.\n","    You should also calculate the number of correct predictions as this is required by calculate_accuracy_batch function.\"\"\"\n","accuracy = tf.reduce_mean(correct_prediction) \n","correct_sum = tf.reduce_sum(correct_prediction) \n","\n","\n","\"\"\" It will be usefull to calculate the numbers and accurracy of correct predictions\n","    also for images of other sizes. \"\"\"\n","# Correct predictions\n","correct_prediction_56 = tf.equal(tf.argmax(logits_56, 1), tf.argmax(y, 1)) \n","correct_prediction_56 = tf.cast(correct_prediction_56, tf.float32) \n","\n","correct_prediction_20 = tf.equal(tf.argmax(logits_20, 1), tf.argmax(y, 1)) \n","correct_prediction_20 = tf.cast(correct_prediction_20, tf.float32) \n","\n","# Accurracies\n","accuracy_56 = tf.reduce_mean(correct_prediction_56) \n","accuracy_20 = tf.reduce_mean(correct_prediction_20) \n","\n","correct_sum_56 = tf.reduce_sum(correct_prediction_56)\n","correct_sum_20 = tf.reduce_sum(correct_prediction_20) "],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"6bxb6jjlCu9s"},"cell_type":"markdown","source":["**3.6 Train our Neural Network**  \n","\n","In this exercise you are asked to train and evaluate the CNN network. Please complete the code for the train function, where:\n","\n","*   `sess` - is the opened tf.Session, you may assume that the global varaibles have been already initialized.\n","*   `x_train` - is the train dataset\n","*   `x_valid` - is the validation dataset. This is not obligatory, but you may use the validation dataset and  \n","the `calculate_accuracy_batch(x_valid, correct_sum,x)` function defined previously, to monitor the network score on out-of-train data.\n","*   `epoch_num` - number of epochs \n","*   `batch_size` - the size of one batch.\n","\n","This function trains on data of size 32x32, 56x56 and 20x20. "]},{"metadata":{"colab_type":"code","id":"AM9Y5Zmi8rPu","colab":{}},"cell_type":"code","source":["def train(sess, X_train, X_valid, y_train, y_valid, epoch_num, batch_size, print_every=1):\n","    val_accs_pooling = []\n","    val_accs_56 = []\n","    val_accs_20 = []\n","    set_size = X_train.shape[0]\n","    global X_train_res_56, y_train_56\n","    global X_train_res_20, y_train_20\n","    for epoch in range(epoch_num):\n","        for i in range(0, set_size, batch_size):\n","            \"\"\"\n","            Complete the training loop.\n","            \"\"\"\n","            ##\n","        \n","        if epoch % print_every == 0:\n","            val_acc = calculate_accuracy_batch(sess, X_valid, y_valid, correct_sum, x)\n","            acc_56 = calculate_accuracy_batch(sess, X_valid_res_56, y_valid, correct_sum_56, x_56)\n","            acc_20 = calculate_accuracy_batch(sess, X_valid_res_20, y_valid, correct_sum_20, x_20)\n","            \n","            val_accs_pooling.append(val_acc)\n","            val_accs_56.append(acc_56)\n","            val_accs_20.append(acc_20)\n","            \n","            print('Epoch: {0:d}, ACC: {1:.3f}, ACC (56): {2:.3f}, ACC (20): {3:.3f}'.format(epoch, val_acc, acc_56, acc_20))\n","        \n","        # shuffle the dataset\n","        perm = np.random.permutation(set_size)\n","        X_train = X_train[perm, :]\n","        y_train = y_train[perm, :]\n","        perm = np.random.permutation(len(X_train_res_56))\n","        X_train_res_56 = X_train_res_56[perm, :]\n","        y_train_56 = y_train_56[perm, :]\n","        perm = np.random.permutation(len(X_train_res_20))\n","        X_train_res_20 = X_train_res_20[perm, :]\n","        y_train_20 = y_train_20[perm, :]\n","        \n","        \n","    san_accuracy = {}\n","    san_accuracy['Acc'] = val_accs_pooling\n","    san_accuracy['Acc_20'] = val_accs_20\n","    san_accuracy['Acc_56'] = val_accs_56\n","    \n","    return san_accuracy"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"fHfVAPgJYAIU"},"cell_type":"markdown","source":["** 3.7 Run the code **  \n","Run the code either using the train function"]},{"metadata":{"colab_type":"code","id":"ykrISbEZCYY-","colab":{}},"cell_type":"code","source":["epoch_num = 15\n","batch_size = 64\n","\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    san_accuracy = train(sess, X_train_res_32, X_valid_res_32, y_train_32, y_valid, epoch_num, batch_size)\n","    test_acc = calculate_accuracy_batch(sess, X_test_res_32, y_test , correct_sum, x)\n","    test_acc_56 = calculate_accuracy_batch(sess, X_test_res_56, y_test, correct_sum_56, x_56)\n","    test_acc_20 = calculate_accuracy_batch(sess, X_test_res_20, y_test,correct_sum_20, x_20)\n","    print(\"Final test accuracy: Original: {0:.3f}, 56x56: {1:.3f}, 20x20: {2:.3f}\".format(test_acc, test_acc_56, test_acc_20))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pGoGWXieSDyl","colab_type":"text"},"cell_type":"markdown","source":["**3.8. Plot the accuracy**"]},{"metadata":{"id":"_DMCWvLCRrBR","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.figure(figsize=(9,7))\n","\n","plt.plot(san_accuracy['Acc'], label='Accuracy (original)')\n","plt.plot(san_accuracy['Acc_20'], label='Accuracy (20x20)')\n","plt.plot(san_accuracy['Acc_56'], label='Accuracy (56x56)')\n","plt.ylim(0.2, 0.8)\n","\n","plt.ylabel(\"Accuracy\")\n","plt.xlabel(\"Epoch\")\n","\n","\n","plt.legend(prop={'size': 15})\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iORcgSh9VB_l","colab_type":"text"},"cell_type":"markdown","source":["** 3.9. Compare the accuracies of CNN with global max pooling and CNN with SAN layer**"]},{"metadata":{"id":"jDTkdsnGRrE_","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.figure(figsize=(12,10))\n","\n","plt.plot(san_accuracy['Acc'], label='Accuracy - SAN (original)')\n","plt.plot(san_accuracy['Acc_56'], label='Accuracy - SAN (56x56)')\n","plt.plot(san_accuracy['Acc_20'], label='Accuracy - SAN (20x20)')\n","\n","plt.plot(max_pool_accuracy['Acc'], label='Accuracy - max pooling (original)')\n","plt.plot(max_pool_accuracy['Acc_56'], label='Accuracy - max pooling  (56x56)')\n","plt.plot(max_pool_accuracy['Acc_20'], label='Accuracy - max pooling  (20x20)')\n","plt.ylim(0.2, 0.8)\n","\n","plt.legend(prop={'size': 15})\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"GFuozYINtcfO","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}